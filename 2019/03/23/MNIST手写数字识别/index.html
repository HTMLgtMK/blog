<!DOCTYPE html>
<html lang="English">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"htmlgtmk.github.io","root":"/blog/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="学过了CNN，就像使用CNN完成一次手写数字的识别过程。这次的CNN网络结果使用LeNet-v5网络结构，不使用tensorflow，推导并编写代码，以便加深印象。 CNN简介卷积层+ReLu池化层全连接层">
<meta property="og:type" content="article">
<meta property="og:title" content="MNIST手写数字识别">
<meta property="og:url" content="http://htmlgtmk.github.io/blog/2019/03/23/MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/index.html">
<meta property="og:site_name" content="GT Blog">
<meta property="og:description" content="学过了CNN，就像使用CNN完成一次手写数字的识别过程。这次的CNN网络结果使用LeNet-v5网络结构，不使用tensorflow，推导并编写代码，以便加深印象。 CNN简介卷积层+ReLu池化层全连接层">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_1.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_2.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_3.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_4.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_5.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_6.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_7.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//mean-accuracy.png">
<meta property="article:published_time" content="2019-03-23T13:51:50.000Z">
<meta property="article:modified_time" content="2019-09-09T05:16:08.266Z">
<meta property="article:author" content="GT">
<meta property="article:tag" content="LeNet-v5 CNN MNIST">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://htmlgtmk.github.io/blog/.io//tuidao_1.png">

<link rel="canonical" href="http://htmlgtmk.github.io/blog/2019/03/23/MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>MNIST手写数字识别 | GT Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/blog/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">GT Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="English">
    <link itemprop="mainEntityOfPage" href="http://htmlgtmk.github.io/blog/2019/03/23/MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="GT">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GT Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MNIST手写数字识别
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-23 21:51:50" itemprop="dateCreated datePublished" datetime="2019-03-23T21:51:50+08:00">2019-03-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-09-09 13:16:08" itemprop="dateModified" datetime="2019-09-09T13:16:08+08:00">2019-09-09</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>学过了CNN，就像使用CNN完成一次手写数字的识别过程。<br>这次的CNN网络结果使用LeNet-v5网络结构，不使用tensorflow，<br>推导并编写代码，以便加深印象。</p>
<h2 id="CNN简介"><a href="#CNN简介" class="headerlink" title="CNN简介"></a>CNN简介</h2><h3 id="卷积层-ReLu"><a href="#卷积层-ReLu" class="headerlink" title="卷积层+ReLu"></a>卷积层+ReLu</h3><h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><a id="more"></a>
<h2 id="LeNet-v5简介"><a href="#LeNet-v5简介" class="headerlink" title="LeNet-v5简介"></a>LeNet-v5简介</h2><p>LeNet-v5共有7层，具体如下：</p>
<ul>
<li>输入图片: 32<em>32</em>1. 图片大小为32像素，1通道。</li>
<li>卷积层：2</li>
<li>池化层(降采样层)：2</li>
<li>全连接层：2</li>
<li>输出：1。手写数字识别中为10种数字的概率。</li>
</ul>
<h3 id="第一层-卷积层"><a href="#第一层-卷积层" class="headerlink" title="第一层 卷积层"></a>第一层 卷积层</h3><ul>
<li>input image size: 28<em>28</em>1</li>
<li>卷积核: 5*5，6个</li>
<li>卷积模式: same</li>
<li>卷积步长: 1</li>
<li>卷积Padding: 0</li>
<li>output image size: 28<em>28</em>6. 图片大小为28*28，共有6张Feature Map.</li>
</ul>
<ul>
<li>参数个数: ((5<em>5)+1)</em>6 = 156. 其中+1是因为需要加入一个偏置。</li>
<li>连接数: 156<em>(28</em>28) = 122304. </li>
</ul>
<h3 id="第二层-平均池化层"><a href="#第二层-平均池化层" class="headerlink" title="第二层 平均池化层"></a>第二层 平均池化层</h3><ul>
<li>input image size: 28<em>28</em>6</li>
<li>卷积核: 2*2</li>
<li>卷积模式: valid</li>
<li>卷积步长: 2</li>
<li>卷积Padding: 0</li>
<li>output image size: 14<em>14</em>6</li>
</ul>
<h3 id="第三层-卷积层"><a href="#第三层-卷积层" class="headerlink" title="第三层 卷积层"></a>第三层 卷积层</h3><ul>
<li>input image size: 14<em>14</em>6. 图片大小为28*28，共有6张Feature</li>
<li>卷积核: 5*5, 16个</li>
<li>卷积模式: valid</li>
<li>卷积步长: 1</li>
<li>卷积Padding: 0</li>
<li>output image size: 10<em>10</em>16</li>
</ul>
<ul>
<li>参数个数: ((5<em>5)+1)</em>16 = 416</li>
</ul>
<h3 id="第四层-最大池化层"><a href="#第四层-最大池化层" class="headerlink" title="第四层 最大池化层"></a>第四层 最大池化层</h3><ul>
<li>input image size: 10<em>10</em>16</li>
<li>卷积核: 2*2</li>
<li>卷积模式: valid</li>
<li>卷积步长: 2</li>
<li>卷积Padding: 0</li>
<li>output image size: 5<em>5</em>16<br><strong>注:</strong> 需要将这一层的输出图片拉直成一维的数据，以适应下一层的输入。</li>
</ul>
<h3 id="第五层-全连接层"><a href="#第五层-全连接层" class="headerlink" title="第五层 全连接层"></a>第五层 全连接层</h3><ul>
<li>input image size: 5<em>5</em>16</li>
<li>output: 120个单元<br>每个单元与第4层中全部400个单元之间进行全连接，<br>如同传统机器学习方法，FC5层计算输入向量与权重向量之间的点积，再加上一个偏置。</li>
</ul>
<ul>
<li>参数个数: 120<em>(5</em>5*16+1) = 48120<br>全连接层的功能是实现分类或者回归(前面的卷积层和池化层的功能是提取图片特征)</li>
</ul>
<h3 id="第六层-全连接层"><a href="#第六层-全连接层" class="headerlink" title="第六层 全连接层"></a>第六层 全连接层</h3><ul>
<li>input: 120单元</li>
<li>output: 84单元<br>每个单元与第5层中全部120个单元之间进行全连接</li>
</ul>
<ul>
<li>参数个数: 84*(120+1) = 10164</li>
</ul>
<h3 id="第七层-Output输出层"><a href="#第七层-Output输出层" class="headerlink" title="第七层 Output输出层"></a>第七层 Output输出层</h3><ul>
<li>input: 84单元</li>
<li>output: 1种类别<br>输出层由<code>欧式径向基函数(Euclidean  Radial Basis Function, RBF)单元</code>组成，<br>每类一个单元，每个有84个输入。</li>
</ul>
<h2 id="CNN推导"><a href="#CNN推导" class="headerlink" title="CNN推导"></a>CNN推导</h2><p><img src="/blog/.io//tuidao_1.png" alt="tuidao_1.png"><br><img src="/blog/.io//tuidao_2.png" alt="tuidao_2.png"><br><img src="/blog/.io//tuidao_3.png" alt="tuidao_3.png"><br><img src="/blog/.io//tuidao_4.png" alt="tuidao_4.png"><br><img src="/blog/.io//tuidao_5.png" alt="tuidao_5.png"><br><img src="/blog/.io//tuidao_6.png" alt="tuidao_6.png"><br><img src="/blog/.io//tuidao_7.png" alt="tuidao_7.png"></p>
<h2 id="tensorflow-lenet实现"><a href="#tensorflow-lenet实现" class="headerlink" title="tensorflow lenet实现"></a>tensorflow lenet实现</h2><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.contrib.slim <span class="keyword">as</span> slim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lenet</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		self.raw_images = tf.placeholder(tf.float32, </span><br><span class="line">							shape=[<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">'images_input'</span>)</span><br><span class="line">		self.raw_labels = tf.placeholder(tf.float32, </span><br><span class="line">							shape=[<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">'labels_input'</span>)</span><br><span class="line">		self.keep_prob = tf.placeholder(tf.float32, name=<span class="string">'keep_prob'</span>)</span><br><span class="line">		<span class="string">''' `&#123;需要修改shape为网络输入的size&#125;`'''</span></span><br><span class="line">		self.images = tf.reshape(self.raw_images, shape=[<span class="number">-1</span>, <span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</span><br><span class="line">		...</span><br><span class="line">		<span class="comment">#### Train ####</span></span><br><span class="line">		...</span><br><span class="line">		<span class="comment">#### `&#123;计算accuracy&#125;` ####</span></span><br><span class="line">		...</span><br><span class="line">		<span class="comment">#### `&#123;计算loss&#125;` ####</span></span><br><span class="line">	&#125;</span><br><span class="line">			</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Lenet-网络实现"><a href="#Lenet-网络实现" class="headerlink" title="Lenet 网络实现"></a>Lenet 网络实现</h3><p>这部分实验了好久，主要的问题是每次训练得到的accuracy过低, 只有0.1左右,<br>一直以为是accuracy的计算方式问题或者是net结构问题, 调整了好久.<br>最终参考github上面star数量最多的两位前辈的代码，终于跑出了像样的accuracy.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/ganyc717/LeNet</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">construct_net2</span><span class="params">(self,is_train=True)</span>:</span></span><br><span class="line">	<span class="keyword">with</span> slim.arg_scope([slim.conv2d], padding=<span class="string">'VALID'</span>,</span><br><span class="line">			weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">			weights_regularizer=slim.l2_regularizer(<span class="number">1e-5</span>)):</span><br><span class="line">		net = slim.conv2d(self.images,<span class="number">6</span>,[<span class="number">5</span>,<span class="number">5</span>],<span class="number">1</span>,padding=<span class="string">'SAME'</span>,scope=<span class="string">'conv1'</span>)</span><br><span class="line">		net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">'pool2'</span>)</span><br><span class="line">		net = slim.conv2d(net,<span class="number">16</span>,[<span class="number">5</span>,<span class="number">5</span>],<span class="number">1</span>,scope=<span class="string">'conv3'</span>)</span><br><span class="line">		net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">'pool4'</span>)</span><br><span class="line">		net = slim.conv2d(net,<span class="number">120</span>,[<span class="number">5</span>,<span class="number">5</span>],<span class="number">1</span>,scope=<span class="string">'conv5'</span>)</span><br><span class="line">		net = slim.flatten(net, scope=<span class="string">'flat6'</span>)</span><br><span class="line">		net = slim.fully_connected(net, <span class="number">84</span>, scope=<span class="string">'fc7'</span>)</span><br><span class="line">		net = slim.dropout(net, <span class="number">0.5</span>, is_training=is_train, scope=<span class="string">'dropout8'</span>)</span><br><span class="line">		digits = slim.fully_connected(net, <span class="number">10</span>, scope=<span class="string">'fc9'</span>)</span><br><span class="line">		<span class="keyword">return</span> digits</span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/xiao-data/lenet</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(self, images, filter, bias, strides=<span class="number">1</span>, padding=<span class="string">"VALID"</span>)</span>:</span></span><br><span class="line">	feat_map = tf.nn.conv2d(images, filter=filter, </span><br><span class="line">		strides=[<span class="number">1</span>, strides, strides, <span class="number">1</span>], padding=padding)</span><br><span class="line">	feat_map = tf.nn.bias_add(feat_map, bias)</span><br><span class="line">	<span class="keyword">return</span> tf.maximum(<span class="number">0.1</span>*feat_map, feat_map)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool2d</span><span class="params">(self, images, strides=<span class="number">2</span>)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> tf.nn.max_pool(images, ksize=[<span class="number">1</span>,strides,strides,<span class="number">1</span>],</span><br><span class="line">		strides=[<span class="number">1</span>,strides,strides,<span class="number">1</span>], padding=<span class="string">"VALID"</span>)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fc</span><span class="params">(self, image, weights, bias)</span>:</span></span><br><span class="line">	feat_img = tf.add(tf.matmul(image, weights), bias)</span><br><span class="line">	<span class="keyword">return</span> tf.maximum(<span class="number">0.1</span>*feat_img, feat_img)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">construct_net</span><span class="params">(self)</span>:</span></span><br><span class="line">	weights = &#123;</span><br><span class="line">		<span class="string">'conv1'</span>: tf.Variable(tf.random_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">6</span>])),</span><br><span class="line">		<span class="string">'conv3'</span>: tf.Variable(tf.random_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">16</span>])),</span><br><span class="line">		<span class="string">'conv5'</span>: tf.Variable(tf.random_normal([<span class="number">5</span>,<span class="number">5</span>,<span class="number">16</span>,<span class="number">120</span>])),</span><br><span class="line">		<span class="string">'fc1'</span> : tf.Variable(tf.random_normal([<span class="number">120</span>, <span class="number">84</span>])),</span><br><span class="line">		<span class="string">'fc2'</span> : tf.Variable(tf.random_normal([<span class="number">84</span>, <span class="number">10</span>]))</span><br><span class="line">	&#125;</span><br><span class="line">	bias = &#123;</span><br><span class="line">		<span class="string">'conv1'</span>: tf.Variable(tf.random_normal([<span class="number">6</span>])),</span><br><span class="line">		<span class="string">'conv3'</span>: tf.Variable(tf.random_normal([<span class="number">16</span>])),</span><br><span class="line">		<span class="string">'conv5'</span>: tf.Variable(tf.random_normal([<span class="number">120</span>])),</span><br><span class="line">		<span class="string">'fc1'</span> : tf.Variable(tf.random_normal([<span class="number">84</span>])),</span><br><span class="line">		<span class="string">'fc2'</span> : tf.Variable(tf.random_normal([<span class="number">10</span>]))</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	conv1 = self.conv2d(self.images, weights[<span class="string">'conv1'</span>], bias[<span class="string">'conv1'</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line">	pool2 = self.max_pool2d(conv1)</span><br><span class="line">	conv3 = self.conv2d(pool2, weights[<span class="string">'conv3'</span>], bias[<span class="string">'conv3'</span>])</span><br><span class="line">	pool4 = self.max_pool2d(conv3)</span><br><span class="line">	conv5 = self.conv2d(pool4, weights[<span class="string">'conv5'</span>], bias[<span class="string">'conv5'</span>])</span><br><span class="line">	flatten = tf.contrib.layers.flatten(conv5)</span><br><span class="line">	fc1 = self.fc(flatten, weights[<span class="string">'fc1'</span>], bias[<span class="string">'fc1'</span>])</span><br><span class="line">	fc2 = self.fc(fc1, weights[<span class="string">'fc2'</span>], bias[<span class="string">'fc2'</span>])</span><br><span class="line">	fc2 = tf.nn.dropout(fc2, keep_prob=self.keep_prob)</span><br><span class="line">	<span class="keyword">return</span> fc2</span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h3 id="Lenet-计算loss"><a href="#Lenet-计算loss" class="headerlink" title="Lenet 计算loss"></a>Lenet 计算loss</h3><p>使用cross_entropy作为loss函数, 并且加入l2_regularization, 使用Adam Optimizer.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.reduce_mean(</span><br><span class="line">	tf.nn.softmax_cross_entropy_with_logits(</span><br><span class="line">		labels=self.raw_labels, </span><br><span class="line">		logits=self.train_output))</span><br><span class="line">l2_loss = tf.contrib.layers.apply_regularization(</span><br><span class="line">	regularizer=tf.contrib.layers.l2_regularizer(<span class="number">0.0005</span>), </span><br><span class="line">	weights_list = tf.trainable_variables())</span><br><span class="line">self.loss = cross_entropy + l2_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># `&#123;对与net2, 0.01学习率太高, 0.00001学习率差不多&#125;`</span></span><br><span class="line">self.train_op = tf.train.AdamOptimizer(<span class="number">1e-3</span>)</span><br><span class="line">	.minimize(self.loss) <span class="comment"># `&#123;科学计数法&#125;`</span></span><br></pre></td></tr></table></figure>
<h3 id="Lenet-计算accuracy"><a href="#Lenet-计算accuracy" class="headerlink" title="Lenet 计算accuracy"></a>Lenet 计算accuracy</h3><p>比较预测得到的输出和原始数据输入labels, 将[True, True, False,…]转换成float.<br>再计算总和求平均.<br><strong>注意: 必须使用和计算loss时使用的output, 否则预测率很低 </strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># `&#123;计算准确性需要使用同一次计算的输出, 否则会出现loss变低. 但是accuracy仍然不高的情况&#125;`</span></span><br><span class="line">self.prediction = tf.nn.softmax(self.train_output, <span class="number">1</span>)</span><br><span class="line">correct_pred = tf.equal(</span><br><span class="line">	tf.argmax(self.prediction, <span class="number">1</span>), </span><br><span class="line">	tf.argmax(self.raw_labels, <span class="number">1</span>))</span><br><span class="line">self.train_accuracy = tf.reduce_mean(</span><br><span class="line">	tf.cast(correct_pred, tf.float32))</span><br></pre></td></tr></table></figure>
<h3 id="Lenet-训练"><a href="#Lenet-训练" class="headerlink" title="Lenet 训练"></a>Lenet 训练</h3><p>加载MNIST数据集, 分批次投喂给Lenet, 打印accuracy和loss.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist \</span><br><span class="line">	<span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">from</span> lenet <span class="keyword">import</span> Lenet</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(argv)</span>:</span></span><br><span class="line">	tf.reset_default_graph()</span><br><span class="line">	<span class="comment"># `&#123;读取数据&#125;`</span></span><br><span class="line">	mnist = input_data.read_data_sets(<span class="string">'MNIST_data/'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">	<span class="comment"># `&#123;训练&#125;`</span></span><br><span class="line">	lenet = Lenet()</span><br><span class="line">	sess = tf.Session()</span><br><span class="line"></span><br><span class="line">	is_trianed = <span class="literal">False</span></span><br><span class="line">	saver = tf.train.Saver()</span><br><span class="line">	model_file = tf.train.latest_checkpoint(<span class="string">"MNIST_model/"</span>)</span><br><span class="line">	<span class="keyword">if</span> model_file != <span class="literal">None</span>:</span><br><span class="line">		saver.restore(sess, model_file)</span><br><span class="line">		is_trianed = <span class="literal">True</span></span><br><span class="line">		print(<span class="string">"restore variables from model file!"</span>)</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> <span class="keyword">not</span> is_trianed:</span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">			batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">			<span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">				train_accuracy, train_loss = sess.run(</span><br><span class="line">					[lenet.train_accuracy, lenet.loss], </span><br><span class="line">					feed_dict=&#123;</span><br><span class="line">					lenet.raw_images: mnist.validation.images[:<span class="number">1000</span>] , lenet.raw_labels: mnist.validation.labels[:<span class="number">1000</span>], lenet.keep_prob:<span class="number">1</span></span><br><span class="line">					&#125;)</span><br><span class="line">				print(<span class="string">"After %d iteration, the loss is %g, the accuracy is %g"</span> % (i, train_loss, train_accuracy))</span><br><span class="line">			<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">		_, output = sess.run(</span><br><span class="line">			[lenet.train_op,lenet.train_output],</span><br><span class="line">			feed_dict=&#123;lenet.raw_images: batch[<span class="number">0</span>], lenet.raw_labels:batch[<span class="number">1</span>], lenet.keep_prob:<span class="number">1</span></span><br><span class="line">		&#125;)</span><br><span class="line">		<span class="comment"># print(output)</span></span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line">	saver.save(sess, <span class="string">"MNIST_model/mnist.ckpt"</span>)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">	print(<span class="string">"Train model success! \</span></span><br><span class="line"><span class="string">		Start test accuracy on test set!"</span>)</span><br><span class="line">	<span class="comment"># `&#123;测试&#125;`</span></span><br><span class="line">	train_accuracy = sess.run(lenet.train_accuracy, feed_dict=&#123;</span><br><span class="line">		lenet.raw_images: mnist.test.images, lenet.raw_labels: mnist.test.labels, lenet.keep_prob: <span class="number">1</span></span><br><span class="line">		&#125;)</span><br><span class="line">	print(<span class="string">"the mean accuracy of test set is %g"</span> % (train_accuracy))</span><br><span class="line">	print(<span class="string">"Process End!"</span>)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">	tf.app.run()</span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><p><img src="/blog/.io//mean-accuracy.png" alt="mean-accuracy.png"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">~/python.exe E:/document/python/Lenet/Train.py</span><br><span class="line">Extracting MNIST_data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting MNIST_data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting MNIST_data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting MNIST_data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">2019-03-30 21:40:19.775733: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2</span><br><span class="line">After 0 iteration, the loss is 26481.4, the accuracy is 0.112</span><br><span class="line">After 100 iteration, the loss is 659.815, the accuracy is 0.164</span><br><span class="line">After 200 iteration, the loss is 437.044, the accuracy is 0.263</span><br><span class="line">After 300 iteration, the loss is 310.122, the accuracy is 0.384</span><br><span class="line">After 400 iteration, the loss is 234.881, the accuracy is 0.469</span><br><span class="line">After 500 iteration, the loss is 194.672, the accuracy is 0.559</span><br><span class="line">...</span><br><span class="line">After 9600 iteration, the loss is 18.8913, the accuracy is 0.949</span><br><span class="line">After 9700 iteration, the loss is 18.5993, the accuracy is 0.946</span><br><span class="line">After 9800 iteration, the loss is 18.8633, the accuracy is 0.943</span><br><span class="line">After 9900 iteration, the loss is 18.4148, the accuracy is 0.94</span><br><span class="line">Train model success! Start test accuracy on test set!</span><br><span class="line">the mean accuracy of test set is 0.9504</span><br><span class="line">Process End!</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/LeNet-v5-CNN-MNIST/" rel="tag"># LeNet-v5 CNN MNIST</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2019/03/15/%E5%B0%8F%E7%B1%B3Android%E5%AE%9E%E4%B9%A0%E9%9D%A2%E8%AF%95/" rel="prev" title="小米Android实习面试">
      <i class="fa fa-chevron-left"></i> 小米Android实习面试
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2019/08/28/lucene%E7%B3%BB%E5%88%97-1-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8/" rel="next" title="lucene系列(1)--入门使用">
      lucene系列(1)--入门使用 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN简介"><span class="nav-number">1.</span> <span class="nav-text">CNN简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积层-ReLu"><span class="nav-number">1.1.</span> <span class="nav-text">卷积层+ReLu</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层"><span class="nav-number">1.2.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层"><span class="nav-number">1.3.</span> <span class="nav-text">全连接层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet-v5简介"><span class="nav-number">2.</span> <span class="nav-text">LeNet-v5简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#第一层-卷积层"><span class="nav-number">2.1.</span> <span class="nav-text">第一层 卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第二层-平均池化层"><span class="nav-number">2.2.</span> <span class="nav-text">第二层 平均池化层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第三层-卷积层"><span class="nav-number">2.3.</span> <span class="nav-text">第三层 卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第四层-最大池化层"><span class="nav-number">2.4.</span> <span class="nav-text">第四层 最大池化层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第五层-全连接层"><span class="nav-number">2.5.</span> <span class="nav-text">第五层 全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第六层-全连接层"><span class="nav-number">2.6.</span> <span class="nav-text">第六层 全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#第七层-Output输出层"><span class="nav-number">2.7.</span> <span class="nav-text">第七层 Output输出层</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN推导"><span class="nav-number">3.</span> <span class="nav-text">CNN推导</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tensorflow-lenet实现"><span class="nav-number">4.</span> <span class="nav-text">tensorflow lenet实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#输入"><span class="nav-number">4.1.</span> <span class="nav-text">输入</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lenet-网络实现"><span class="nav-number">4.2.</span> <span class="nav-text">Lenet 网络实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lenet-计算loss"><span class="nav-number">4.3.</span> <span class="nav-text">Lenet 计算loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lenet-计算accuracy"><span class="nav-number">4.4.</span> <span class="nav-text">Lenet 计算accuracy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lenet-训练"><span class="nav-number">4.5.</span> <span class="nav-text">Lenet 训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#运行结果"><span class="nav-number">4.6.</span> <span class="nav-text">运行结果</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">GT</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">GT</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  















  

  

</body>
</html>
