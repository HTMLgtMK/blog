<!DOCTYPE html>
<html lang="English">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"htmlgtmk.github.io","root":"/blog/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="这篇文章记录了阅读 MapReduce: Simplified Data Processing on Large Clusters 的 Points. 这篇论文在 2004 年就已经发表，作者是 Jeffrey  Gean ( 杰夫-迪恩 ) 和 Sanjay Ghemawat ( 桑杰-格玛沃特 ) . 两个都是 Goolgle 公司的大牛。 AbstractMapReduce 是一个编程模型">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce-阅读">
<meta property="og:url" content="http://htmlgtmk.github.io/blog/2019/10/31/MapReduce-%E9%98%85%E8%AF%BB/index.html">
<meta property="og:site_name" content="GT Blog">
<meta property="og:description" content="这篇文章记录了阅读 MapReduce: Simplified Data Processing on Large Clusters 的 Points. 这篇论文在 2004 年就已经发表，作者是 Jeffrey  Gean ( 杰夫-迪恩 ) 和 Sanjay Ghemawat ( 桑杰-格玛沃特 ) . 两个都是 Goolgle 公司的大牛。 AbstractMapReduce 是一个编程模型">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//Figure1.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//Figure2.png">
<meta property="og:image" content="http://htmlgtmk.github.io/blog/.io//Figure3.png">
<meta property="article:published_time" content="2019-10-31T02:19:24.000Z">
<meta property="article:modified_time" content="2019-11-01T03:32:45.891Z">
<meta property="article:author" content="GT">
<meta property="article:tag" content="MapReduce">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://htmlgtmk.github.io/blog/.io//Figure1.png">

<link rel="canonical" href="http://htmlgtmk.github.io/blog/2019/10/31/MapReduce-%E9%98%85%E8%AF%BB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>MapReduce-阅读 | GT Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/blog/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">GT Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="English">
    <link itemprop="mainEntityOfPage" href="http://htmlgtmk.github.io/blog/2019/10/31/MapReduce-%E9%98%85%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="GT">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GT Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MapReduce-阅读
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-31 10:19:24" itemprop="dateCreated datePublished" datetime="2019-10-31T10:19:24+08:00">2019-10-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-01 11:32:45" itemprop="dateModified" datetime="2019-11-01T11:32:45+08:00">2019-11-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>这篇文章记录了阅读 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters</a> 的 Points.</p>
<p>这篇论文在 2004 年就已经发表，作者是 Jeffrey  Gean ( 杰夫-迪恩 ) 和 Sanjay Ghemawat ( 桑杰-格玛沃特 ) . 两个都是 <em>Goolgle</em> 公司的大牛。</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>MapReduce 是一个编程模型 ( programming model ) 和 用于 处理和生成 大型数据集的相关实现。</p>
<a id="more"></a>
<p>Users specify a <strong><em>map</em></strong> function that processes a <em>key/value pair</em> to generate a set of intermediate key/value pairs, and a <strong><em>reduce</em></strong> function that merges all intermediate values associated with the same intermediate key. </p>
<p>使用本文这种功能形式的程序自动具有并行能力，并且可以执行在由廉价机器组成的大型集群上。</p>
<p>The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling machine failures, and managing the required inter-machine communication. </p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>The major contributions of this work are a simple and powerful interface that enables automatic parallelization and distribution of large-scale computations, combined with an implementation of this interface that achieves high performance on large clusters of commodity PCs.</p>
<h2 id="2-Programming-Model"><a href="#2-Programming-Model" class="headerlink" title="2. Programming Model"></a>2. Programming Model</h2><p><em>Input</em>: a set of key/value pairs.</p>
<p><em>Output</em>: a set of key/value pairs.</p>
<p>用户使用 MapReduce Library 表达计算只使用 两个功能： <em>Map</em> and <em>Reduce</em>。</p>
<p><strong><em>Map</em></strong>: 由 user 编写，takes an input pair and produces a set of <em>intermediate</em> key/value pairs. MapReduce Library 将 中间结果键值对利用相同的键值 <em>I</em> 分组( groups together ), 并且将他们传送到 <em>Reduce</em> 函数。</p>
<p><strong><em>Reduce</em></strong>: 也由 user 编写，接收一个中间键值 <em>I</em> 以及该键值下的一组值（ a set of values for that key）. Reduce 将这些 values 合并，形成 ( form) 一个（可能）更小的一组集合(a possibly smaller set of values)。典型的 每个Reduce 产生 0个或1个输出值。中间值通过一个 iterator 提供给 user’s reduce function. 这样我们可以处理一些超过内存大小的大型数据集。</p>
<h3 id="2-1-Example"><a href="#2-1-Example" class="headerlink" title="2.1 Example"></a>2.1 Example</h3><p>这一部分不是很重要，主要裂了一些 MapReduce  的应用。可以先跳过这部分，直接看 MapReduce 是如何实现的。</p>
<p>Consider the problem of counting the number of occurrences of each word in a large collection of documents. </p>
<p>则可能的 pseudo-code 如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">map(String key, String value):</span><br><span class="line">	<span class="comment">// key: document name</span></span><br><span class="line">	<span class="comment">// value: document content</span></span><br><span class="line">	<span class="keyword">for</span> each word w in value:</span><br><span class="line">		EmitIntermediate(w, <span class="string">"1"</span>);</span><br><span class="line"></span><br><span class="line">reduce(String key, Iterator values):</span><br><span class="line">	<span class="comment">// key: a word</span></span><br><span class="line">	<span class="comment">// values: a  list of counts</span></span><br><span class="line">	<span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> each v in values:</span><br><span class="line">		result += ParseInt(v);</span><br><span class="line">	Emit(AsString(result));</span><br></pre></td></tr></table></figure>
<p>map 函数发出每个单词和一个相关的出现次数计数(在这个简单的示例中只有“1”)。reduce 函数将为特定单词发出的所有计数汇总在一起。</p>
<p>额外的，用户还需要指定输入输出的文件名以填充 <em>mapreduce speciffication</em>  对象，并且指定某些可选的优化参数。然后用户再激活 <em>mapReduce</em> 函数，传递 该对象给它。然后再与 MapReduce Library 链接（由 C++ 实现）。这个示例的完整代码在 附录A 里面。</p>
<h3 id="2-2-Types"><a href="#2-2-Types" class="headerlink" title="2.2 Types"></a>2.2 Types</h3><p>尽管前面的伪代码是根据字符串输入和输出编写的，但从概念上讲，用户提供的map和reduce函数具有关联的类型：</p>
<blockquote>
<p>map           (  k1, v1 )                 -&gt; list ( k2, v2 )</p>
<p>reduce      ( k2, list ( v2 ))         -&gt; list( v2 )</p>
</blockquote>
<p>例如： Input 的 key/value  类型 和 Output 的 key/value 类型可以不同，而 中间值的 key/value 类型 和 Output 的 key/value 类型相同。</p>
<h3 id="2-3-More-Examples"><a href="#2-3-More-Examples" class="headerlink" title="2.3 More Examples"></a>2.3 More Examples</h3><ol>
<li><strong>Distributed Grep</strong>:  The map function emits a line if it matches a supplied pattern. The reduce function is an identity function that just copies the supplied intermediate data to the output</li>
<li><strong>Count of URL Access Frequency</strong>： The map function processes logs of web page requests and outputs <em><URL, 1></URL,></em>. The reduce function adds together all values for the same URL and emits a <em><URL, total count></URL,></em> pair.</li>
<li><strong>Reverse Web-Link Graph</strong>: The map function outputs <target, source> pairs for each link to a <em>target</em> URL found in a page named <em>source</em>. The reduce function concatenates the list of all source URLs associated with a given target URL and emits the pair: <em><target, list(source)></target,></em>.</target,></li>
<li><strong>Term-Vector per Host</strong>: A term vector summarizes the most important words that occur in a document or a set of documents as a list of <em><word, frequency></word,></em> pairs. The map function emits a <em><hostname, term vector></hostname,></em> pair for each input document (where the hostname is extracted from the URL of the document). The reduce function is passed all per-document term vectors for a given host. It adds these term vectors together, throwing away infrequent terms, and then emits a final <em><hostname, term vector></hostname,></em> pair.</li>
<li><strong>Inverted Index</strong>:  The map function parses each document, and emits a sequence of <em><word, document id></word,></em> pairs. The reduce function accepts all pairs for a given word, sorts the corresponding document IDs and emits a <em><word, list(document id)></word,></em> pair. The set of all output pairs forms a simple inverted index. It is easy to augment this computation to keep track of word positions.</li>
<li><strong>Distributed Sort</strong>: The map function extracts the key from each record, and emits a <em><key, record></key,></em> pair. The reduce function emits all pairs unchanged. This computation depends on the partitioning facilities described in Section 4.1 and the ordering properties described in Section 4.2</li>
</ol>
<h2 id="3-Implementation"><a href="#3-Implementation" class="headerlink" title="3. Implementation"></a>3. Implementation</h2><p>可能存在多种的 MapReduce 实现，正确的做法是根据环境决定选用哪个实现。例如，某种实现适用于 a small share-memory machine, 而另一个适用于 a large NUMA multi-processor, 还有的可能适用于 an even larger collection of networked machines.</p>
<p>这里讨论的只是 Google 内部广泛使用的环境下：large clusters of commodity PCs connected together with switched Ethernet。</p>
<h3 id="3-1-Execution-Overview"><a href="#3-1-Execution-Overview" class="headerlink" title="3.1 Execution Overview"></a>3.1 Execution Overview</h3><p>Figure 1 shows the overall flow of a MapReduce operation in our implementation. When the user program calls the <em>MapReduce</em> function, the following sequence of actions occurs (the numbered labels in Figure 1 correspond to the numbers in the list below): </p>
<p><img src="/blog/.io//Figure1.png" alt="Figure1.png"></p>
<ol>
<li><p>用户程序中的 MapReduce library 首先将输入文件分割成 M 份，典型的每份大小为 16 MB ~ 64 MB ( 可以由用户通过可选参数控制 )。然后在集群的机器上启动多个相同拷贝的程序（copies of the programe）。</p>
</li>
<li><p>其中的一个程序拷贝是特殊的—Master，另外的都称为 <em>worker</em>, 由 <em>master</em> 分派任务。 . There are M map tasks and R reduce tasks to assign. Master 选取静默的 workers，并为每个 worker 分派一个 map 任务 或者 reduce 任务。</p>
</li>
<li><p>如果一个 worker 被分派的是 <em>map</em> task, 那么它将读取相对应的输入文件的 split 的内容。将输入文件内容解析成 key/value 键值对形式，并传递到 user-defined <em>Map</em> function.  The intermediate Key/Value 键值对由 <em>Map</em> 函数产生，并且 buffered in memory。</p>
</li>
<li><p>每个周期（Periodically）, 缓存的 key/value 键值对将被写入到 local disk，并被 <em>partitioning function</em> 被分割成 <em>R</em> 份。这些存到本地磁盘的 buffered key/value pairs 的 locations 将传递回 master. Master 负责分发这些 locations 到 reduce workers.</p>
<p>“who is responsible for forwarding these locations to the reduce workers”</p>
</li>
<li><p>当一个 reduce worker 接收到 master 通知的 locations 信息，it uses remote procedure calls to read the buffered data from the local disk of the map workers.  当 reduce worker  读取到所有的 intermediate data, 它将这些数据按照 intermediate keys 排序，这样具有相同 key 的 occurrences 值就可以 grouped together.  排序是必要的，因为典型的有很多的不同的 keys 被 map 到 相同的 reduce task. 如果 intermediate data 太大以至于超出内存容量，则可以使用 external sort.</p>
</li>
<li><p>reduce worker 遍历 排序后的 intermediate data, 并且对每个遇到的唯一的 intermediate key ，传递 这个 key 值和对应的 intermediate data 集合 到 user’s <em>Reduce</em> function. <em>Reduce</em> function 的输出将追加到 a final output file for this reduce partition.</p>
</li>
<li><p>当所有的 map tasks 和 reduce tasks 都已经完成， master 唤醒 user programe.  At this point, the MapReduce call in the user program returns back to the user code。</p>
</li>
</ol>
<p>成功完成后，mapreduce 的执行输出可以在 <em>R</em> 份输出文件中找到。一般的，用户不将这 <em>R</em> 份文件合并成 一个文件，而是将其作为下一个 MapReduce 调用的输入，或者其他可以处理这些文件的分布式应用。</p>
<h3 id="3-2-Master-Data-Structures"><a href="#3-2-Master-Data-Structures" class="headerlink" title="3.2 Master Data Structures"></a>3.2 Master Data Structures</h3><p>The master keeps several data structures. 对每个 map task 和 reduce task, master 保存它们的状态（<em>idle, in-progress, or completed</em>), 并且保存 worker machine 的标识( identity )。</p>
<p>Master 作为 map task 到 reduce task 中间值的传送管道（conduit）。对每个已经完成的 map task, the master 存储 这 <em>R</em> 个 intermediate file regions 的 locations 和 sizes. 当 map task 完成时，这些 locations 和 sizes 信息将会被更新，这些信息也会增量( incrementally )的推送给 <em>in-progress</em> 的 reduce worker.</p>
<h3 id="3-3-Fault-Tolerance"><a href="#3-3-Fault-Tolerance" class="headerlink" title="3.3 Fault Tolerance"></a>3.3 Fault Tolerance</h3><p><strong>Worker Failure</strong></p>
<p>Master 周期性的 ping 每个 worker. 如果没有在一个确定的时间内收到 response, 那么 master 标记这个 worker 已经 failed. 任何已经完成 map task 的 worker 将会被重置为初始的 <em>idle</em> 状态， and therefore become eligible for scheduling on other workers. 类似的，任何 map task 或 reduce task 失败的 worker 也会被重置为 <em>idle</em> 状态，并且 become eligible for rescheduling.</p>
<p><strong>在发生故障时将重新执行已完成的 map 任务( completed map task )，因为它们的输出存储在故障机器的本地磁盘上，因此无法访问。已经完成的 reduce 任务不需要重新执行，因为它们的输出存储在全局文件系统中。</strong></p>
<p>当一个 map task 先由 worker A 执行，再由 worker B 执行（因为 A 执行失败了），所有执行 reduce tasks 的 workers 将被通知 re-execution. 任何还没有从 worker A 读取数据的 reduce task 将从 worker B 读取数据。</p>
<p>MapReduce is resilient to large-scale worker failures. 通过简单的重新执行由不可达机器的 task, 然后向前推进，最终完成 MapReduce operation.</p>
<p><strong>Master Failure</strong></p>
<p>It is easy to make the master write <strong>periodic checkpoints</strong> of the master data structures described above. A new copy can be started from the last checkpoint state.</p>
<p>Our current implementation <strong>aborts</strong> the MapReduce computation if the master fails.</p>
<p><strong>Semantics in the Presence of Failures</strong></p>
<p>When the user-supplied <em>map</em> and <em>reduce</em> operators are deterministic functions of their input values, our distributed implementation produces the same output as would have been produced by a non-faulting sequential execution of the entire program.</p>
<p>We rely on atomic commits of map and reduce task outputs to achieve this property. Each in-progress task writes its output to private temporary files. A reduce task produces one such file, and a map task produces R such files (one per reduce task).</p>
<p>We rely on the atomic rename operation provided by the underlying file system to guarantee that the final file system state contains just the data produced by one execution of the reduce task.</p>
<p>When the map and/or reduce operators are nondeterministic, we provide weaker but still reasonable semantics.  在存在非确定性操作符的情况下，特定 reduce 任务 <em>R1</em> 的输出与非确定性程序的顺序执行所产生的 <em>R1</em> 的输出相等。但是，不同reduce 任务 <em>R2</em> 的输出可能对应于不确定程序的不同顺序执行所产生的 <em>R2</em> 输出。</p>
<h3 id="3-4-Locality"><a href="#3-4-Locality" class="headerlink" title="3.4 Locality"></a>3.4 Locality</h3><p>Network bandwidth is a relatively scarce resource in our computing environment. 我们通过利用输入数据存储在集群机器本地磁盘上（ GFS ）的优点来节省网络带宽。</p>
<p>The MapReduce master takes the location information of the input files into account and attempts to schedule a map task on a machine that contains a replica of the corresponding input data. Failing that, it attempts to schedule a map task near a replica of that task’s input data.</p>
<p>当在集群中相当一部分 worker 上运行大型 MapReduce 操作时，大多数输入数据都是在本地读取的，不会消耗网络带宽。</p>
<h3 id="3-5-Task-Granularity-任务粒度"><a href="#3-5-Task-Granularity-任务粒度" class="headerlink" title="3.5 Task Granularity ( 任务粒度 )"></a>3.5 Task Granularity ( 任务粒度 )</h3><p>我们继续细分 map 阶段为 <em>M</em> 份， reduce 阶段 为 <em>R</em> 份，如上所述。理想状况下，<em>M</em> 和 <em>R</em> 应该远大于 worker machines 的数量。让每个 worker 执行许多不同的任务可以改进动态负载平衡，并在一个 worker 失败时加速恢复: 它已经完成的许多 map 任务可以分布在所有其他worker机器上.</p>
<p>在我们的实现中，<em>M</em> 和 <em>R</em> 的大小是有实际界限的，因为 主机 必须做出 <em>O(M + R)</em> 调度决策，并将 <em>O(M\</em>R)<em>  状态保存在内存中，如上所述。并且用户通常会限制 </em>R* ，因为每个 reduce task 最后都将输出一个独立文件。</p>
<p>实际上，我们倾向于选择 <em>M</em> 使得每个独立的任务 大约接收 16 MB ~ 64 MB 的输入数据（使得上面提到的 locality optimization 最有效）。让 <em>R</em> 为 一个小的乘子（ a small） 乘以 我们希望的 worker 的数量。</p>
<p>We often perform MapReduce computations with M = 200, 000 and R = 5, 000, using 2,000 worker machines.</p>
<h3 id="3-6-Backup-Tasks"><a href="#3-6-Backup-Tasks" class="headerlink" title="3.6 Backup Tasks"></a>3.6 Backup Tasks</h3><p>延长MapReduce操作所需总时间的常见原因之一是“掉队者( straggler )”：计算中完成最后几个 map 或 reduce 任务中的一个需要异常长的时间的机器。掉队者的出现有很多原因。例如，有一个坏磁盘的机器可能会经常出现可纠正的错误，这会将其读取性能从 30 MB/s 降低到 1 MB/s。集群调度系统可能已经调度了机器上的其他任务，由于CPU、内存、本地磁盘或网络带宽的竞争，导致它执行 MapReduce 代码的速度更慢。我们最近遇到的一个问题是机器初始化代码中的一个bug，它导致处理器缓存（ processor cache ）被禁用:受影响机器上的计算速度降低了100多倍。</p>
<p>我们有一个通用的机制 ( general mechanism ) 来缓解( alleviate )掉队者的问题。当一个 MapReduce 操作接近完成时，主进程会调度仍然 in-progress tasks 的备份执行( backup executions )  。当主执行或备份执行完成时，任务被标记为已完成( completed )。我们对这个机制进行了调优，因此它通常只将操作所使用的计算资源增加不超过几个百分点。我们发现这大大减少了完成大型 MapReduce 操作的时间。例如，当禁用备份任务机制时，第5.3节中描述的排序程序需要多花费 44% 的时间才能完成。</p>
<h2 id="4-Refinements"><a href="#4-Refinements" class="headerlink" title="4. Refinements"></a>4. Refinements</h2><p>尽管通过简单的编写 <em>Map</em> 和 <em>Reduce</em> 函提供的基本功能已经可以满足大部分的需求，我们发现一些 extensions 很有用。</p>
<h3 id="4-1-Partitioning-Function"><a href="#4-1-Partitioning-Function" class="headerlink" title="4.1 Partitioning Function"></a>4.1 Partitioning Function</h3><p>The users of MapReduce specify the number of reduce tasks/output files that they desire <em>(R)</em>. 数据在这些任务上首先需要在 intermediate key 上划分。一个默认的划分函数( partitioning function )是使用 哈希函数（e.g. Hash(key) mod R ). 这个划分函数 tends to result in fairly well-balanced partitions. </p>
<p>然而，通过一些其他的划分函数比较有效。例如，有时，输出键是 URLs ，我们希望单个主机的所有条目都在同一个输出文件中结束。为了支持这种情况，MapReduce 库的用户可以提供一个特殊的划分函数。例如使用 <em>hash(Hostname(urlkey)) mnod R</em> 作为划分函数，这样所有来自相同 host 的 URLs 都出现在一个输出文件中。</p>
<h3 id="4-2-Ordering-Guarantees"><a href="#4-2-Ordering-Guarantees" class="headerlink" title="4.2 Ordering Guarantees"></a>4.2 Ordering Guarantees</h3><p>我们保证在给定的分区中，<strong>中间键/值对按递增键顺序处理</strong>。这种排序保证可以很容易地为每个分区生成一个排序的输出文件，这在输出文件格式需要支持高效的按键随机访问查找，或者输出的用户发现排序数据很方便时非常有用。</p>
<h3 id="4-3-Combiner-Function"><a href="#4-3-Combiner-Function" class="headerlink" title="4.3 Combiner Function"></a>4.3 Combiner Function</h3><p>In some cases, there is significant repetition in the intermediate keys produced by each <em>map task, and the userspecified </em>Reduce* function is commutative and associative. </p>
<p>We allow the user to specify an optional <em>Combiner</em> function that does partial merging of this data before it is sent over the network. 通常 <em>Combiner</em>   和 <em>Reduce</em> 使用相同的一套代码，两者唯一不同的地方是 MapReduce library 如何处理这个函数的输出。The output of a reduce function is written to the final output file. The output of a combiner function is written to an intermediate file that will be sent to a reduce task。</p>
<p>部分 combine 显著的加速了 几个 MapReduce 操作的类。</p>
<h3 id="4-4-Input-and-Output-Types"><a href="#4-4-Input-and-Output-Types" class="headerlink" title="4.4 Input and Output Types"></a>4.4 Input and Output Types</h3><p>The MapReduce Library 支持读取多种格式的输入数据。例如，”text” 模式的输入将 each line 视作一个 key/value 键值对：key 是 the offset in the file, value 是 the content of the  line. </p>
<p>用户可以支持新的读取格式，通过提供 一个 <em>reader</em> 接口的简单实现。A reader does not necessarily need to provide data read from a file. 也可以从 数据库 或者 内存中获取数据。</p>
<p>类似的，我们支持一组输出类型，并且用户很容易的添加新的输出类型。</p>
<h3 id="4-5-Side-effects"><a href="#4-5-Side-effects" class="headerlink" title="4.5 Side-effects"></a>4.5 Side-effects</h3><p>In some cases, users of MapReduce have found it convenient to produce auxiliary files as additional outputs from their map and/or reduce operators. 我们依靠 the application writer 去原子的幂等的（ idempotent）实现这样的 副产物 。通常应用先将数据写入临时文件，全部写入后再将临时文件原子的 重命名。</p>
<p>我们不支持单任务生成的多个输出文件的原子两阶段提交。因此，产生具有跨文件一致性要求的多个输出文件的任务应该是确定的。这一限制在实践中从未成为问题。</p>
<h3 id="4-6-Skipping-Bad-Records"><a href="#4-6-Skipping-Bad-Records" class="headerlink" title="4.6 Skipping Bad Records"></a>4.6 Skipping Bad Records</h3><p>用户程序有时会存在 Bug，导致 <em>Map</em> 或 <em>Reduce</em> 在 某些 records 上 crash. 这样的 bug 会使得 MapReduce 不能正常的完成。  The usual course of action is to fix the bug；also, sometimes it is acceptable to ignore a few records.  我们提供一个可选的执行模式（ an optional mode of execution ），MapReduce library会检测哪些 records 导致确定的 crash，然后将跳过这些 records ，以能够继续向前运行。</p>
<p>Each worker process installs a signal handler that catches segmentation violations and bus errors。在激活 user’s Map or Reduce 函数之前，MapReduce 库会将参数的序列号存储在一个全局变量中。如果用户的代码产生了一个 signal，那么  the signal handler 将发送一个 “last gasp” UDP packet 给 master，packet 中包含由 sequence number. 当主机在一个特定的 record 上看到由多于一次的 failure，那么它表示这个 record 需要在下一次重新执行时被跳过。</p>
<h3 id="4-7-Local-Execution"><a href="#4-7-Local-Execution" class="headerlink" title="4.7 Local Execution"></a>4.7 Local Execution</h3><p>Debugging problems in <em>Map</em> or <em>Reduce</em> functions can be tricky, since the actual computation happens in a distributed system,</p>
<p>为了方便 debug, profiling, 以及 small-scale testing, 我们在 MapReduce 库中提供了一个可选的实现，可以在一个本地机器上面串行的执行所有的 MapReduce 操作。用户可以控制 computation 局限于某些特定的 map task。用户使用一个特殊的标志来调用他们的程序，然后可以轻松地使用任何他们认为有用的调试或测试工具(例如gdb)。</p>
<h3 id="4-8-Status-Information"><a href="#4-8-Status-Information" class="headerlink" title="4.8 Status Information"></a>4.8 Status Information</h3><p>主机内部包含一个 HTTP server，并且导出一组 status pages 供人们了解。Status pages 显示了计算的进度，例如已经有多少 tasks 完成，还有多少正在执行，输入数据的大小，中间数据的大小，输出数据的大小，处理的数据等。页面还提供到每个 task 生成的 standard error 和 standard output files 的链接(links)。用户可以利用这些信息来预测计算还需要多长时间，是否需要增添计算资源等。页面还可以用于计算 computation 是否慢于 预期。</p>
<p>另外， Top-level 的状态页面可以显示哪个 worker have failed, 以及当它们执行哪个 map task 或者 reduce task 时 failed, 这些信息有利于诊断用户代码中的 bug。</p>
<h3 id="4-9-Counters"><a href="#4-9-Counters" class="headerlink" title="4.9 Counters"></a>4.9 Counters</h3><p>The MapReduce library provides a counter facility to count occurrences of various events. 例如，用户代码可能想要 count the total number of words processed. </p>
<p>为了使用这一便利，用户代码可以创建一个 counter object，然后在 Map/Reduce 中合适的递增 counter。 例如：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Counter* uppercase;</span><br><span class="line">uppercase = GetCounter(<span class="string">"uppercase"</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">map</span>(<span class="keyword">String</span> name, <span class="keyword">String</span> contents):</span><br><span class="line">	<span class="keyword">for</span> each <span class="keyword">word</span> w in contents:</span><br><span class="line">		<span class="keyword">if</span> (IsCapitalized(w)):</span><br><span class="line">			uppercase-&gt;Increment();</span><br><span class="line">		EmitIntermediate(w, <span class="string">"1"</span>);</span><br></pre></td></tr></table></figure>
<p>在 worker machine 上面的 counter values 会周期性的传播到 master（ piggybacked on the ping response ）。The master aggregates the counter values from successful map and reduce tasks and returns them to the user code when the MapReduce operation is completed.  当前的 counter values 也会显示在 status page上面，人们可以实时的看到计算过程。当聚合计数器值时，主进程消除相同映射的重复执行或减少任务的影响，以避免重复计数。</p>
<h2 id="5-Performance"><a href="#5-Performance" class="headerlink" title="5. Performance"></a>5. Performance</h2><ul>
<li>任务1： 在大约 1 TB 数据中查找某个 pattern 下的的数据。</li>
<li>任务2： 在大约 1 TB 数据上排序。</li>
</ul>
<h3 id="5-1-Cluster-Configuration"><a href="#5-1-Cluster-Configuration" class="headerlink" title="5.1 Cluster Configuration"></a>5.1 Cluster Configuration</h3><h3 id="5-2-Grep"><a href="#5-2-Grep" class="headerlink" title="5.2 Grep"></a>5.2 Grep</h3><p>标题的意思就是 UNIX 系统中的 grep 工具。</p>
<p><em>grep</em> 程序扫描 10^10 100-byte records, 查找相对稀少的3字符模式（该模式大约出现 92.337次）。输入数据将切分成大约 64 MB 每份（M = 15000）, 整个程序输出到一个文件（R = 1）。</p>
<p><img src="/blog/.io//Figure2.png" alt="Figure2.png"></p>
<h3 id="5-3-Sort"><a href="#5-3-Sort" class="headerlink" title="5.3 Sort"></a>5.3 Sort</h3><p><em>sort</em> 程序排序 10^10 100-byte records( 大约 1 TB 数据 )。This program is modeled after the TeraSort benchmark 。</p>
<p><img src="/blog/.io//Figure3.png" alt="Figure3.png"></p>
<h3 id="5-4-Effect-of-Backup-Tasks"><a href="#5-4-Effect-of-Backup-Tasks" class="headerlink" title="5.4 Effect of Backup Tasks"></a>5.4 Effect of Backup Tasks</h3><p>从Figure3(b) 中可以看到，执行曲线于Figure3(a) 十分类似，但是 Figure3(b) 有一个十分长的尾巴。</p>
<h3 id="5-5-Machine-Failures"><a href="#5-5-Machine-Failures" class="headerlink" title="5.5 Machine Failures"></a>5.5 Machine Failures</h3><p>从 Figure 3(c) 中可以看到，在 killed 200 woker之后，隐藏的 cluster scheduler 立即重启了新的 worker processes .</p>
<p>The worker deaths show up as a negative input rate since some previously completed map work disappears (since the corresponding map workers were killed) and needs to be redone.  The re-execution of this map work happens relatively quickly. </p>
<h2 id="6-Experience"><a href="#6-Experience" class="headerlink" title="6. Experience"></a>6. Experience</h2><p>It has been used across a wide range of domains within Google, including:</p>
<ul>
<li>large-scale machine learning problems,</li>
<li>clustering problems for the Google News and Froogle products</li>
<li>extraction of data used to produce reports of popular queries (e.g. Google Zeitgeist),</li>
<li>extraction of properties of web pages for new experiments and products (e.g. extraction of geographical locations from a large corpus of web pages for localized search), and</li>
<li>large-scale graph computations.</li>
</ul>
<h2 id="7-Relate-Work"><a href="#7-Relate-Work" class="headerlink" title="7. Relate Work"></a>7. Relate Work</h2><h2 id="8-Conclusions"><a href="#8-Conclusions" class="headerlink" title="8. Conclusions"></a>8. Conclusions</h2>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/MapReduce/" rel="tag"># MapReduce</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2019/10/28/GFS-%E9%98%85%E8%AF%BB/" rel="prev" title="GFS 阅读">
      <i class="fa fa-chevron-left"></i> GFS 阅读
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2019/11/04/BigTable-%E9%98%85%E8%AF%BB/" rel="next" title="BigTable-阅读">
      BigTable-阅读 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-number">2.</span> <span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Programming-Model"><span class="nav-number">3.</span> <span class="nav-text">2. Programming Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Example"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 Example</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Types"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 Types</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-More-Examples"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 More Examples</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Implementation"><span class="nav-number">4.</span> <span class="nav-text">3. Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Execution-Overview"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 Execution Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Master-Data-Structures"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 Master Data Structures</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-Fault-Tolerance"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 Fault Tolerance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-Locality"><span class="nav-number">4.4.</span> <span class="nav-text">3.4 Locality</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-Task-Granularity-任务粒度"><span class="nav-number">4.5.</span> <span class="nav-text">3.5 Task Granularity ( 任务粒度 )</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-6-Backup-Tasks"><span class="nav-number">4.6.</span> <span class="nav-text">3.6 Backup Tasks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Refinements"><span class="nav-number">5.</span> <span class="nav-text">4. Refinements</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Partitioning-Function"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 Partitioning Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-Ordering-Guarantees"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 Ordering Guarantees</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-Combiner-Function"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 Combiner Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-Input-and-Output-Types"><span class="nav-number">5.4.</span> <span class="nav-text">4.4 Input and Output Types</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-5-Side-effects"><span class="nav-number">5.5.</span> <span class="nav-text">4.5 Side-effects</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-6-Skipping-Bad-Records"><span class="nav-number">5.6.</span> <span class="nav-text">4.6 Skipping Bad Records</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-7-Local-Execution"><span class="nav-number">5.7.</span> <span class="nav-text">4.7 Local Execution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-8-Status-Information"><span class="nav-number">5.8.</span> <span class="nav-text">4.8 Status Information</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-9-Counters"><span class="nav-number">5.9.</span> <span class="nav-text">4.9 Counters</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Performance"><span class="nav-number">6.</span> <span class="nav-text">5. Performance</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-Cluster-Configuration"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 Cluster Configuration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-Grep"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 Grep</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-Sort"><span class="nav-number">6.3.</span> <span class="nav-text">5.3 Sort</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-Effect-of-Backup-Tasks"><span class="nav-number">6.4.</span> <span class="nav-text">5.4 Effect of Backup Tasks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-Machine-Failures"><span class="nav-number">6.5.</span> <span class="nav-text">5.5 Machine Failures</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Experience"><span class="nav-number">7.</span> <span class="nav-text">6. Experience</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Relate-Work"><span class="nav-number">8.</span> <span class="nav-text">7. Relate Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-Conclusions"><span class="nav-number">9.</span> <span class="nav-text">8. Conclusions</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">GT</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">GT</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  















  

  

</body>
</html>
